# -*- coding: utf-8 -*-
"""Streamlit Dashboard for Policy Status Analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j8u42K4Q721ky8vaIv0qG5NXyNbf77mt
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
import io
import base64

# --- Configuration and Data Preprocessing ---

# Set wide layout for the dashboard
st.set_page_config(layout="wide", page_title="Policy Status Prediction & Insights")

# Mapping the target labels for clarity
TARGET_LABELS = {0: 'Approved Death Claim', 1: 'Repudiate Death'}

# Use Streamlit caching to speed up data loading and processing
@st.cache_data
def load_and_preprocess_data(data_path="Insurance.csv"):
    """Loads, cleans, imputes, and encodes the dataset."""
    try:
        df = pd.read_csv(data_path)
    except FileNotFoundError:
        st.error("Error: Insurance.csv not found. Please ensure the file is in the root directory.")
        return pd.DataFrame(), None, None, None

    # 1. Initial Cleaning and Feature Selection
    df = df.drop(columns=['POLICY_NO', 'PI_NAME'])

    # 2. Cleaning Numerical Columns
    def clean_currency(series):
        return series.astype(str).str.replace(',', '', regex=False).str.strip().replace('', np.nan).astype(float)

    df['SUM_ASSURED'] = clean_currency(df['SUM_ASSURED'])
    df['PI_ANNUAL_INCOME'] = clean_currency(df['PI_ANNUAL_INCOME'])

    # 3. Imputation (using mode for PI_OCCUPATION and REASON_FOR_CLAIM)
    for col in ['PI_OCCUPATION', 'REASON_FOR_CLAIM']:
        imputer = SimpleImputer(strategy='most_frequent')
        df[col] = imputer.fit_transform(df[[col]])[:, 0]

    # Impute numerical features with median/mean if any remaining NaNs exist
    df['SUM_ASSURED'].fillna(df['SUM_ASSURED'].median(), inplace=True)
    df['PI_ANNUAL_INCOME'].fillna(df['PI_ANNUAL_INCOME'].median(), inplace=True)

    # 4. Label Encode the Target Variable
    le = LabelEncoder()
    df['POLICY_STATUS_ENCODED'] = le.fit_transform(df['POLICY_STATUS'])
    df_clean = df.drop(columns=['POLICY_STATUS']).rename(columns={'POLICY_STATUS_ENCODED': 'POLICY_STATUS'})

    # Store original data for the Insights tab
    df_insights = df.copy()

    # 5. One-Hot Encode features for Modeling
    X = df_clean.drop(columns=['POLICY_STATUS'])
    y = df_clean['POLICY_STATUS']
    X_categorical = X.select_dtypes(include=['object']).columns
    X_encoded = pd.get_dummies(X, columns=X_categorical, drop_first=True)

    return df_insights, X_encoded, y, le

# Function to train all models
@st.cache_data(show_spinner="Training classification models...")
def train_models(X, y, le):
    """Trains DT, RF, and GBRT models and returns them along with feature sets."""
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    models = {
        'Decision Tree': DecisionTreeClassifier(random_state=42),
        'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),
        'GBRT': GradientBoostingClassifier(random_state=42, n_estimators=100)
    }

    trained_models = {}
    for name, model in models.items():
        model.fit(X_train, y_train)
        trained_models[name] = model

    return trained_models, X_train, X_test, y_train, y_test, X.columns, le

# --- Model Performance Tab Logic ---

def generate_performance_metrics(trained_models, X_train, X_test, y_train, y_test, le):
    """Calculates and displays all performance metrics and ROC curve."""
    st.subheader("Classification Model Performance (Test Data)")

    results = {}
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    # Create ROC Plot holder
    fig_roc = go.Figure()
    fig_roc.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)

    for name, model in trained_models.items():
        # Cross-validation for robust training metric
        cv_accuracy = np.mean(cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1))

        # Test Predictions
        y_test_pred = model.predict(X_test)
        y_test_proba = model.predict_proba(X_test)[:, 1]

        # Calculate metrics
        test_accuracy = accuracy_score(y_test, y_test_pred)
        precision = precision_score(y_test, y_test_pred)
        recall = recall_score(y_test, y_test_pred)
        f1 = f1_score(y_test, y_test_pred)
        auc = roc_auc_score(y_test, y_test_proba)

        # ROC Curve Data
        fpr, tpr, _ = roc_curve(y_test, y_test_proba)

        # Add to Plotly figure
        fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, name=f'{name} (AUC: {auc:.4f})', mode='lines'))

        # Store results
        results[name] = {
            'Training Accuracy (CV=5)': f"{cv_accuracy:.4f}",
            'Testing Accuracy': f"{test_accuracy:.4f}",
            'Precision': f"{precision:.4f}",
            'Recall': f"{recall:.4f}",
            'F1-Score': f"{f1:.4f}",
            'AUC': f"{auc:.4f}"
        }

    # Finalize ROC plot
    fig_roc.update_layout(
        xaxis_title='False Positive Rate',
        yaxis_title='True Positive Rate (Recall)',
        title='ROC Curve Comparison',
        legend_title='Algorithm'
    )

    # Display Metrics Table
    metrics_df = pd.DataFrame.from_dict(results, orient='index')
    st.dataframe(metrics_df, use_container_width=True)

    # Display ROC Plot
    st.plotly_chart(fig_roc, use_container_width=True)


# --- Prediction Tab Logic ---

def make_predictions(df_to_predict, trained_models, feature_columns, le, df_insights_cols):
    """Cleans, encodes new data and makes predictions."""

    df = df_to_predict.copy()

    # 1. Clean Numerical Columns (Same as training)
    def clean_currency(series):
        return series.astype(str).str.replace(',', '', regex=False).str.strip().replace('', np.nan).astype(float)

    df['SUM_ASSURED'] = clean_currency(df['SUM_ASSURED'])
    df['PI_ANNUAL_INCOME'] = clean_currency(df['PI_ANNUAL_INCOME'])

    # Drop columns not used in training (if they exist)
    if 'POLICY_NO' in df.columns: df.drop(columns=['POLICY_NO'], inplace=True)
    if 'PI_NAME' in df.columns: df.drop(columns=['PI_NAME'], inplace=True)
    if 'POLICY_STATUS' in df.columns: df.drop(columns=['POLICY_STATUS'], inplace=True)

    # 2. Imputation (using a placeholder for robustness, though real-world models would use fitted imputers)
    # For simplicity, we use the mode imputation logic from the training data within the cached function.
    # In a production app, the *fitted* imputers and encoders must be saved and loaded.

    # Re-use the data from the cached function to get mode values for imputation
    df_insights, X_encoded, y, le_ref = load_and_preprocess_data()

    for col in ['PI_OCCUPATION', 'REASON_FOR_CLAIM']:
        mode_val = df_insights[col].mode()[0]
        df[col].fillna(mode_val, inplace=True)

    df['SUM_ASSURED'].fillna(df_insights['SUM_ASSURED'].median(), inplace=True)
    df['PI_ANNUAL_INCOME'].fillna(df_insights['PI_ANNUAL_INCOME'].median(), inplace=True)


    # 3. One-Hot Encode features (critical: must align with training data columns)
    X_categorical = df.select_dtypes(include=['object']).columns
    df_encoded = pd.get_dummies(df, columns=X_categorical, drop_first=True)

    # 4. Align Columns (Add missing columns as 0, drop extra columns)
    missing_cols = set(feature_columns) - set(df_encoded.columns)
    for c in missing_cols:
        df_encoded[c] = 0
    df_final = df_encoded[feature_columns]

    # 5. Predict using Random Forest (chosen as the best performing model by AUC)
    best_model = trained_models['Random Forest']
    predictions = best_model.predict(df_final)
    predictions_proba = best_model.predict_proba(df_final)[:, 1]

    # 6. Prepare output for download
    output_df = df_to_predict.copy()
    output_df['Predicted Status (Encoded)'] = predictions
    output_df['Predicted Policy Status'] = le.inverse_transform(predictions)
    output_df['Repudiate Probability (RF)'] = [f"{p:.4f}" for p in predictions_proba]

    return output_df


def get_table_download_link(df, filename, text):
    """Generates a link allowing the data in a given pandas DataFrame to be downloaded."""
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode()).decode()  # bytes to base64
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">{text}</a>'
    return href


# --- Main Application Layout ---

# Load and prepare data and models
df_insights, X_encoded, y, le = load_and_preprocess_data()
trained_models, X_train, X_test, y_train, y_test, feature_cols, _ = train_models(X_encoded, y, le)

st.title("ðŸ›¡ï¸ Insurance Policy Status Prediction Dashboard")
st.markdown("This application provides data insights and machine learning model evaluation for Policy Status analysis.")

# Create tabs
tab_insights, tab_model, tab_predict = st.tabs(["ðŸ“Š Policy Insights", "ðŸ”¬ Model Performance", "â¬†ï¸ New Prediction"])


# --- Tab 1: Policy Insights ---
with tab_insights:
    st.header("Policyholder Profile and Claim Analysis")

    if df_insights.empty:
        st.stop()

    # --- Filters ---

    st.sidebar.header("Filter Data")

    # Job Role Filter (Multi-select)
    all_occupations = sorted(df_insights['PI_OCCUPATION'].unique())
    selected_occupations = st.sidebar.multiselect(
        "Filter by Job Role (PI_OCCUPATION)",
        all_occupations,
        default=all_occupations[:5] # Select a few by default
    )

    # Age Slider Filter (Proxy for life stage/experience)
    min_age = int(df_insights['PI_AGE'].min())
    max_age = int(df_insights['PI_AGE'].max())
    age_range = st.sidebar.slider(
        "Filter by Age Range (PI_AGE)",
        min_value=min_age,
        max_value=max_age,
        value=(min_age, max_age),
        step=1
    )

    # Apply filters
    filtered_df = df_insights[
        (df_insights['PI_OCCUPATION'].isin(selected_occupations)) &
        (df_insights['PI_AGE'] >= age_range[0]) &
        (df_insights['PI_AGE'] <= age_range[1])
    ]

    if filtered_df.empty:
        st.warning("No data matches the selected filters. Please adjust the filters.")
        st.stop()

    st.info(f"Displaying data for **{len(filtered_df)}** policies based on filters.")


    col1, col2 = st.columns(2)

    # --- Chart 1: Distribution of Annual Income by Policy Status (Violin Plot) ---
    with col1:
        st.subheader("1. Income Distribution vs. Policy Status")
        fig1 = px.violin(
            filtered_df,
            y="PI_ANNUAL_INCOME",
            x="POLICY_STATUS",
            color="POLICY_STATUS",
            box=True, # Add a box plot inside the violin
            log_y=True, # Use log scale for income due to potential skew
            title="Policy Status by Log-Transformed Annual Income"
        )
        fig1.update_layout(xaxis_title="", yaxis_title="PI Annual Income (Log Scale)")
        st.plotly_chart(fig1, use_container_width=True)

    # --- Chart 2: Policy Count by Zone and Policy Status (Stacked Bar) ---
    with col2:
        st.subheader("2. Policy Status by Zone")
        zone_status = filtered_df.groupby(['ZONE', 'POLICY_STATUS']).size().reset_index(name='Count')
        fig2 = px.bar(
            zone_status,
            x="ZONE",
            y="Count",
            color="POLICY_STATUS",
            title="Policy Status Count Across Different Zones",
            barmode='stack'
        )
        fig2.update_layout(xaxis_title="Zone", yaxis_title="Policy Count")
        st.plotly_chart(fig2, use_container_width=True)


    col3, col4 = st.columns(2)

    # --- Chart 3: Repudiation Rate by Top Claim Reasons (Donut Chart) ---
    with col3:
        st.subheader("3. Top Claim Reasons for Repudiated Policies")
        repudiated_df = filtered_df[filtered_df['POLICY_STATUS'] == 'Repudiate Death']
        top_reasons = repudiated_df['REASON_FOR_CLAIM'].value_counts().head(5).index
        repudiation_reasons = repudiated_df[repudiated_df['REASON_FOR_CLAIM'].isin(top_reasons)]

        # Create a simple pie chart (donut)
        fig3 = px.pie(
            repudiation_reasons,
            names='REASON_FOR_CLAIM',
            title=f'Distribution of Top {len(top_reasons)} Repudiation Reasons',
            hole=0.3
        )
        st.plotly_chart(fig3, use_container_width=True)

    # --- Chart 4: Sunburst of Payment Mode, Early/Non-Early, and Policy Status ---
    with col4:
        st.subheader("4. Hierarchy of Payment Mode and Timing")
        fig4 = px.sunburst(
            filtered_df,
            path=['PAYMENT_MODE', 'EARLY_NON', 'POLICY_STATUS'],
            values='SUM_ASSURED',
            title='Sum Assured Distribution by Payment Mode and Claim Timing',
            color='POLICY_STATUS'
        )
        st.plotly_chart(fig4, use_container_width=True)


    # --- Chart 5: Scatter Plot of Age vs. Sum Assured (Complex Insight) ---
    st.subheader("5. Policy Status by Age and Sum Assured (Actionable Insight)")
    fig5 = px.scatter(
        filtered_df,
        x="PI_AGE",
        y="SUM_ASSURED",
        color="POLICY_STATUS",
        size="PI_ANNUAL_INCOME", # Use income as size for a third variable
        hover_data=['PI_OCCUPATION', 'REASON_FOR_CLAIM'],
        title="Policy Status: Age vs. Sum Assured (Size=Annual Income)"
    )
    fig5.update_layout(yaxis_title="Sum Assured (Log Scale)", xaxis_title="Policyholder Age")
    fig5.update_yaxes(type="log")
    st.plotly_chart(fig5, use_container_width=True)

    st.markdown("""
    ---
    **Actionable Insights for Management (Based on Charts):**
    * **Income (Chart 1):** Policies with status 'Repudiate Death' appear to have a slightly lower median annual income compared to 'Approved Death Claim'. **Action:** Investigate underwriting criteria on lower-income groups for potential bias or missed risk factors.
    * **Zone (Chart 2):** Analyze zones with high total repudiated claims (e.g., TEAM HIMALAYAN) to understand regional risk factors or operational consistency in claim processing.
    * **Claim Reason (Chart 3):** Focus risk mitigation and policy wording around the top repudiation reasons (e.g., Suicide, Heart Attack).
    * **Age/Sum Assured (Chart 5):** Look for clusters of 'Repudiate Death' claims among specific age/sum assured groups. These clusters represent high-risk segments needing re-evaluation.
    """)

# --- Tab 2: Model Performance ---
with tab_model:
    st.header("Machine Learning Model Evaluation")
    st.markdown("""
    Click the button below to re-run the three classification algorithms (Decision Tree, Random Forest, GBRT) on the cleaned training and testing data.
    The results include comprehensive metrics (Accuracy, Precision, Recall, F1-Score, AUC) on the test data.
    """)

    if st.button("Run Model Training and Evaluation"):
        generate_performance_metrics(trained_models, X_train, X_test, y_train, y_test, le)
    else:
        st.info("Click the button to generate the model performance charts and table.")

# --- Tab 3: Prediction & Upload ---
with tab_predict:
    st.header("Predict Policy Status on New Data")
    st.markdown("Upload a new CSV file with the same structure as the original data to predict the Policy Status (Approved Death Claim or Repudiate Death).")

    uploaded_file = st.file_uploader("Choose a CSV file", type="csv")

    if uploaded_file is not None:
        try:
            new_df = pd.read_csv(uploaded_file)
            st.success(f"File uploaded successfully! {len(new_df)} rows loaded.")
            st.dataframe(new_df.head(), use_container_width=True)

            if st.button("Predict Policy Status (using Random Forest)"):
                # Use the existing data prep, models, and feature columns
                predicted_df = make_predictions(new_df, trained_models, feature_cols, le, df_insights.columns)

                st.subheader("Prediction Results")
                st.dataframe(predicted_df, use_container_width=True)

                # Download link
                st.markdown(
                    get_table_download_link(predicted_df, "predicted_policy_status.csv", "â¬‡ï¸ Download Predicted Data"),
                    unsafe_allow_html=True
                )
                st.info("The predictions were made using the Random Forest model, which had the highest AUC value (best overall discriminatory power) in the evaluation.")

        except Exception as e:
            st.error(f"An error occurred during file processing or prediction: {e}")